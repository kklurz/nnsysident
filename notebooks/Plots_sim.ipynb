{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datajoint as dj\n",
    "dj.config['database.host'] = os.environ['DJ_HOST']\n",
    "dj.config['database.user'] = os.environ['DJ_USER']\n",
    "dj.config['database.password'] = os.environ['DJ_PASS']\n",
    "dj.config['enable_python_native_blobs'] = True\n",
    "\n",
    "name = \"simdata\"\n",
    "dj.config['schema_name'] = f\"konstantin_nnsysident_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import nnfabrik\n",
    "from nnfabrik.main import *\n",
    "from nnfabrik import builder\n",
    "from nnfabrik.utility.hypersearch import Bayesian\n",
    "\n",
    "from mlutils.measures import corr\n",
    "\n",
    "from nnsysident.tables.experiments import *\n",
    "from nnsysident.tables.bayesian import *\n",
    "from nnsysident.datasets.mouse_loaders import static_shared_loaders\n",
    "from nnsysident.datasets.mouse_loaders import static_loaders\n",
    "from nnsysident.datasets.mouse_loaders import static_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer(old_experiment_name):\n",
    "    # prepare the Transfer table in a way that all the info about the transferred model is in the DataFrame. Just pd.merge (on transfer_fn and transfer_hash)\n",
    "    # it then with the model that the transferred model was used for. \n",
    "    transfer = pd.DataFrame(Transfer.fetch())\n",
    "    transfer = pd.concat([transfer, transfer['transfer_config'].apply(pd.Series)], axis = 1).drop('transfer_config', axis = 1)\n",
    "\n",
    "    tm = pd.DataFrame((TrainedModel * Dataset * Seed * Experiments.Restrictions & 'experiment_name = \"{}\"'.format(old_experiment_name)).fetch()).rename(\n",
    "        columns = {'model_hash': 't_model_hash', 'trainer_hash': 't_trainer_hash', 'dataset_hash': 't_dataset_hash'})\n",
    "    tm = tm.sort_values('score', ascending=False).drop_duplicates(['t_model_hash', 't_trainer_hash', 't_dataset_hash'])\n",
    "\n",
    "    transfer = pd.merge(transfer, tm, how='inner', on=['t_model_hash', 't_trainer_hash', 't_dataset_hash'])\n",
    "    transfer = pd.concat([transfer, transfer['dataset_config'].apply(pd.Series)], axis = 1).drop('dataset_config', axis = 1)\n",
    "    transfer.columns = ['t_' + col if col[:2] != 't_' and col[:8] != 'transfer'  else col for col in transfer.columns]\n",
    "    transfer = transfer.sort_values(['t_neuron_n', 't_image_n', 't_neuron_base_seed', 't_image_base_seed'])\n",
    "    return transfer\n",
    "\n",
    "def baseline(data, tier):\n",
    "    \"\"\" Function to estimate the highest possible correlation based on the ground truth\"\"\"\n",
    "    # get dataset\n",
    "    for loc, row in data_.iterrows():\n",
    "        dataset_config = row['dataset_config']\n",
    "        dataset_config.update(seed=1)\n",
    "        dataloaders = builder.get_data(row['dataset_fn'], dataset_config)\n",
    "        dataset = dataloaders['train']['0-0-3-0'].dataset\n",
    "        dataset.transforms = []\n",
    "        break\n",
    "    # Extract data\n",
    "    idx = dataset.trial_info.tiers == tier\n",
    "    gts = np.array([gt for gt in dataset.neurons.ground_truths]).T[idx]\n",
    "    resps = np.array([datapoint.responses for datapoint in dataset])[idx]\n",
    "    # Compute correlation and return\n",
    "    return np.mean(corr(resps, gts, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for experiment_name in ['SIM, Direct, se2d_spatialxfeaturelinear, 0-0-3', 'SIM, Direct, se2d_pointpooled, 0-0-3', 'SIM, Direct, se2d_fullgaussian2d, 0-0-3']:\n",
    "    data_ = pd.DataFrame((TrainedModel * Dataset * Model * Trainer * Seed * Experiments.Restrictions & 'experiment_name=\"{}\"'.format(experiment_name)).fetch())\n",
    "    data = pd.concat([data, data_])\n",
    "    \n",
    "data = pd.concat([data, data['dataset_config'].apply(pd.Series)], axis = 1).drop('dataset_config', axis = 1)\n",
    "data = pd.concat([data, data['model_config'].apply(pd.Series)], axis = 1).drop('model_config', axis = 1)\n",
    "data['readout'] = [row.model_fn.split('.')[-1] for loc, row in data.iterrows()]\n",
    "base_line = baseline(data=data, tier='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Directly trained'\n",
    "neuron_n = 1000\n",
    "\n",
    "hues = np.unique(data.readout.values)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "sns.set_context('talk', font_scale=1.45)\n",
    "pal = sns.color_palette('colorblind', n_colors=len(hues))\n",
    "sns.set_palette(pal)\n",
    "with sns.axes_style('ticks'):\n",
    "    g = sns.pointplot('image_n', \"score\", hue='readout', data=data.loc[data['neuron_n'] == neuron_n], \n",
    "                hue_order=hues, ax=ax)\n",
    "    plt.axhline(base_line, c='k', ls='--', label='baseline')\n",
    "    g.set_ylim(0.3, 1.0)\n",
    "    sns.despine(trim=True)\n",
    "    g.axes.set_ylabel('validation correlation') \n",
    "    g.axes.set_xlabel('images') \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(0.99, 0.05), ncol=1, frameon=False, prop={'size': 15.})\n",
    "    plt.title(title)\n",
    "    \n",
    "    g.figure.savefig('sim: ' + title + '.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### core-transfer (sameNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for experiment_name in [\"SIM, core_transfer (sameNI), se2d_fullgaussian2d, 0-0-3 -> 0-0-3\",\n",
    "                        \"SIM, core_transfer (sameNI), se2d_pointpooled, 0-0-3 -> 0-0-3\",\n",
    "                        \"SIM, core_transfer (sameNI), se2d_spatialxfeaturelinear, 0-0-3 -> 0-0-3\"]:\n",
    "    data_ = pd.DataFrame((TrainedModelTransfer * Dataset * Model * Trainer * Seed * Transfer.proj() * ExperimentsTransfer.Restrictions & 'experiment_name=\"{}\"'.format(experiment_name)).fetch())\n",
    "    transfer = get_transfer(old_experiment_name='SIM, Direct, {}, 0-0-3'.format(experiment_name.split(', ')[2]))\n",
    "    data_ = pd.merge(data_, transfer, how='inner', on=['transfer_hash', 'transfer_fn'])\n",
    "    data = pd.concat([data, data_])\n",
    "data['readout'] = [row.model_fn.split('.')[-1] for loc, row in data.iterrows()]\n",
    "base_line = baseline(data=data, tier='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Transfer: same #N, #I'\n",
    "t_neuron_n = 1000\n",
    "\n",
    "hues = np.unique(data.readout.values)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "sns.set_context('talk', font_scale=1.45)\n",
    "pal = sns.color_palette('colorblind', n_colors=len(hues))\n",
    "sns.set_palette(pal)\n",
    "with sns.axes_style('ticks'):\n",
    "    g = sns.pointplot('t_image_n', \"score\", hue='readout', data=data.loc[data['t_neuron_n'] == t_neuron_n], \n",
    "                hue_order=hues, ax=ax)\n",
    "    plt.axhline(base_line, c='k', ls='--', label='baseline')\n",
    "    g.set_ylim(0.3, 1.0)\n",
    "    sns.despine(trim=True)\n",
    "    g.axes.set_ylabel('validation correlation') \n",
    "    g.axes.set_xlabel('images (transfer core and new readout)') \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(0.99, 0.05), ncol=1, frameon=False, prop={'size': 15.})\n",
    "    plt.title(title)\n",
    "    \n",
    "    g.figure.savefig('sim: ' + title + '.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### core-transfer (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for experiment_name in [\"SIM, core_transfer (best), se2d_fullgaussian2d, 0-0-3 -> 0-0-3\",\n",
    "                         \"SIM, core_transfer (best), se2d_pointpooled, 0-0-3 -> 0-0-3\",\n",
    "                         \"SIM, core_transfer (best), se2d_spatialxfeaturelinear, 0-0-3 -> 0-0-3\"]:\n",
    "    data_ = pd.DataFrame((TrainedModelTransfer * Dataset * Model * Trainer * Seed * Transfer.proj() * ExperimentsTransfer.Restrictions & 'experiment_name=\"{}\"'.format(experiment_name)).fetch())\n",
    "    transfer = get_transfer(old_experiment_name='SIM, Direct, {}, 0-0-3'.format(experiment_name.split(', ')[2]))\n",
    "    data_ = pd.merge(data_, transfer, how='inner', on=['transfer_hash', 'transfer_fn'])\n",
    "    data = pd.concat([data, data_])\n",
    "data['readout'] = [row.model_fn.split('.')[-1] for loc, row in data.iterrows()]\n",
    "data = pd.concat([data, data['dataset_config'].apply(pd.Series)], axis = 1).drop('dataset_config', axis = 1)\n",
    "base_line = baseline(data=data, tier='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Transfer: best core'\n",
    "neuron_n = 1000\n",
    "\n",
    "hues = np.unique(data.readout.values)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.45)\n",
    "pal = sns.color_palette('colorblind', n_colors=len(hues))\n",
    "sns.set_palette(pal)\n",
    "with sns.axes_style('ticks'):\n",
    "    g = sns.pointplot('image_n', \"score\", hue='readout', data=data.loc[data['neuron_n'] == neuron_n], \n",
    "                hue_order=hues, ax=ax)\n",
    "    plt.axhline(base_line, c='k', ls='--', label='baseline')\n",
    "    g.set_ylim(0.3, 1.0)\n",
    "    sns.despine(trim=True)\n",
    "    g.axes.set_ylabel('validation correlation') \n",
    "    g.axes.set_xlabel('images (new readout)') \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(0.99, 0.05), ncol=1, frameon=False, prop={'size': 15.})\n",
    "    plt.title(title)\n",
    "    \n",
    "    g.figure.savefig('sim: ' + title + '.png', dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
