{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datajoint as dj\n",
    "dj.config['database.host'] = os.environ['DJ_HOST']\n",
    "dj.config['database.user'] = os.environ['DJ_USERNAME']\n",
    "dj.config['database.password'] = os.environ['DJ_PASSWORD']\n",
    "dj.config['enable_python_native_blobs'] = True\n",
    "dj.config['display.limit'] = 200\n",
    "        \n",
    "name = 'mvi'\n",
    "os.environ[\"DJ_SCHEMA_NAME\"] = f\"metrics_{name}\"\n",
    "dj.config[\"nnfabrik.schema_name\"] = os.environ[\"DJ_SCHEMA_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting konstantin@134.76.19.44:3306\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle \n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"figure.facecolor\"] = 'w'\n",
    "mpl.rcParams[\"axes.facecolor\"] = 'w'\n",
    "mpl.rcParams[\"savefig.facecolor\"] = 'w'\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "mpl.rcParams[\"figure.figsize\"] = (3, 3)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "from nnsysident.training.trainers import standard_trainer\n",
    "from nnsysident.models.models import SE2DFullGaussian2d_Poisson, SE2DFullGaussian2d_ZIG, SE2DFullGaussian2d_ZIL\n",
    "from nnsysident.models.ensemble_models import Ensemble\n",
    "from nnsysident.utility.data_helpers import extract_data_key\n",
    "from nnsysident.datasets.mouse_loaders import static_loaders\n",
    "\n",
    "from neuralpredictors.measures.zero_inflated_losses import ZIGLoss, ZILLoss\n",
    "from neuralpredictors.measures import corr\n",
    "\n",
    "from dataport.bcm.static import PreprocessedMouseData\n",
    "\n",
    "random_seed = 27121992\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model architecture configurations\n",
    "with open('group233_model_configs.pkl', 'rb') as handle:\n",
    "    zhiwei_configs = pickle.load(handle)\n",
    "    \n",
    "modulator_kwargs = zhiwei_configs[\"mod_key\"]\n",
    "shifter_kwargs = zhiwei_configs[\"shift_key\"]\n",
    "modulator_kwargs[\"bias\"] = False\n",
    "shifter_kwargs[\"bias\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets =  [{'animal_id': 26614,\n",
    "              'session': 1,\n",
    "              'scan_idx': 16,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 26614,\n",
    "              'session': 2,\n",
    "              'scan_idx': 17,\n",
    "              'scan_purpose': 'dei_control_pair'},\n",
    "             {'animal_id': 26726,\n",
    "              'session': 6,\n",
    "              'scan_idx': 11,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 26726,\n",
    "              'session': 7,\n",
    "              'scan_idx': 13,\n",
    "              'scan_purpose': 'dei_control_pair'},\n",
    "             {'animal_id': 26942,\n",
    "              'session': 1,\n",
    "              'scan_idx': 11,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 26942,\n",
    "              'session': 2,\n",
    "              'scan_idx': 8,\n",
    "              'scan_purpose': 'dei_control_pair'},\n",
    "             {'animal_id': 27468,\n",
    "              'session': 3,\n",
    "              'scan_idx': 12,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 27468,\n",
    "              'session': 4,\n",
    "              'scan_idx': 7,\n",
    "              'scan_purpose': 'dei_control_pair'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagenet_key = datasets[0]\n",
    "assert imagenet_key[\"scan_purpose\"] == \"imagenet\"\n",
    "paths = [\"./data/static{}-{}-{}-GrayImageNet-7bed7f7379d99271be5d144e5e59a8e7.zip\".format(imagenet_key[\"animal_id\"], imagenet_key[\"session\"], imagenet_key[\"scan_idx\"])]\n",
    "img_data_key = extract_data_key(paths[0])\n",
    "\n",
    "dataset_config = {'paths': paths, \n",
    "                  'batch_size': 64, \n",
    "                  'seed': random_seed,\n",
    "                  'loader_outputs': [\"images\", \"responses\", \"pupil_center\", \"behavior\"],\n",
    "                  # 'loader_outputs': [\"images\", \"responses\"],\n",
    "                  'normalize': True,\n",
    "                  'exclude': [\"images\"],\n",
    "                  'subtract_behavior_mean': True\n",
    "                  }\n",
    "    \n",
    "img_dataloaders = static_loaders(**dataset_config)\n",
    "img_dataset = img_dataloaders[\"test\"][img_data_key].dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ZIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for random_seed in np.arange(5):\n",
    "#     loc = np.exp(-10)\n",
    "\n",
    "#     zig_model_config = {\n",
    "#         \"layers\": 4,\n",
    "#         \"hidden_channels\": 64,\n",
    "#         \"feature_reg_weight\": 0.78,\n",
    "#         \"init_mu_range\": 0.55,\n",
    "#         \"init_sigma\": 0.4,\n",
    "#         'grid_mean_predictor': {'type': 'cortex',\n",
    "#                                   'input_dimensions': 2,\n",
    "#                                   'hidden_layers': 0,\n",
    "#                                   'hidden_features': 0,\n",
    "#                                   'final_tanh': False},\n",
    "#         'zero_thresholds': {img_data_key: loc},\n",
    "\n",
    "#         \"input_kern\": 15,\n",
    "#         \"gamma_input\": 1,\n",
    "#         \"hidden_kern\": 13,\n",
    "#         \"depth_separable\": True,\n",
    "#         \"k_image_dependent\": True,\n",
    "#         \"modulator_kwargs\": modulator_kwargs,\n",
    "#         \"shifter_kwargs\": shifter_kwargs,\n",
    "#     }\n",
    "\n",
    "\n",
    "#     zig_model = SE2DFullGaussian2d_ZIG().build_model(img_dataloaders, random_seed, **zig_model_config)\n",
    "#     zig_model.to(device);\n",
    "\n",
    "#     score, output, state_dict = standard_trainer(zig_model,\n",
    "#                                                img_dataloaders,\n",
    "#                                                random_seed, \n",
    "#                                                loss_function=\"ZIGLoss\", \n",
    "#                                                stop_function=\"get_loss\", \n",
    "#                                                track_training=False, \n",
    "#                                                maximize=False)\n",
    "#     zig_model.eval();\n",
    "#     torch.save(state_dict, \"ZIG_statedict\" + img_data_key + f\"-seed{random_seed}\" + \".inshallah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loc = np.exp(-10)\n",
    "\n",
    "zig_model_config = {\n",
    "    \"layers\": 4,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"feature_reg_weight\": 0.78,\n",
    "    \"init_mu_range\": 0.55,\n",
    "    \"init_sigma\": 0.4,\n",
    "    'grid_mean_predictor': {'type': 'cortex',\n",
    "                              'input_dimensions': 2,\n",
    "                              'hidden_layers': 0,\n",
    "                              'hidden_features': 0,\n",
    "                              'final_tanh': False},\n",
    "    'zero_thresholds': {img_data_key: loc},\n",
    "\n",
    "    \"input_kern\": 15,\n",
    "    \"gamma_input\": 1,\n",
    "    \"hidden_kern\": 13,\n",
    "    \"depth_separable\": True,\n",
    "    \"k_image_dependent\": True,\n",
    "    \"modulator_kwargs\": modulator_kwargs,\n",
    "    \"shifter_kwargs\": shifter_kwargs,\n",
    "}\n",
    "\n",
    "\n",
    "zig_model = SE2DFullGaussian2d_ZIG().build_model(img_dataloaders, random_seed, **zig_model_config)\n",
    "zig_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score, output, state_dict = standard_trainer(zig_model,\n",
    "                                           img_dataloaders,\n",
    "                                           random_seed, \n",
    "                                           loss_function=\"ZIGLoss\", \n",
    "                                           stop_function=\"get_loss\", \n",
    "                                           track_training=True, \n",
    "                                           maximize=False)\n",
    "zig_model.eval();\n",
    "# torch.save(state_dict, \"ZIG_statedict\" + img_data_key + \".inshallah\")\n",
    "\n",
    "\n",
    "# zig_model.load_state_dict(torch.load(\"ZIG_statedict\" + img_data_key + \".inshallah\"))\n",
    "# zig_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_correlation: 0.29963976\n",
    "\n",
    "zig_val_loss: -16377972.0\n",
    "\n",
    "zig_train_loss: -150074690.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for random_seed in np.arange(5):\n",
    "\n",
    "#     poisson_model_config = {\n",
    "#         \"layers\": 4,\n",
    "#         \"hidden_channels\": 64,\n",
    "#         \"gamma_readout\": 0.78,\n",
    "#         \"init_mu_range\": 0.55,\n",
    "#         \"init_sigma\": 0.4,\n",
    "#         'grid_mean_predictor': {'type': 'cortex',\n",
    "#                                   'input_dimensions': 2,\n",
    "#                                   'hidden_layers': 0,\n",
    "#                                   'hidden_features': 0,\n",
    "#                                   'final_tanh': False},\n",
    "#         \"input_kern\": 15,\n",
    "#         \"gamma_input\": 1,\n",
    "#         \"hidden_kern\": 13,\n",
    "#         \"depth_separable\": True,\n",
    "#         \"modulator_kwargs\": modulator_kwargs,\n",
    "#         \"shifter_kwargs\": shifter_kwargs,  \n",
    "#     }\n",
    "\n",
    "\n",
    "#     poisson_model = SE2DFullGaussian2d_Poisson().build_model(img_dataloaders, random_seed, **poisson_model_config)\n",
    "#     poisson_model.to(device);\n",
    "\n",
    "#     score, output, state_dict = standard_trainer(poisson_model,\n",
    "#                                                  img_dataloaders,\n",
    "#                                                  random_seed,\n",
    "#                                                  loss_function=\"PoissonLoss\",\n",
    "#                                                  track_training=False, )\n",
    "#     poisson_model.eval();\n",
    "#     torch.save(state_dict, \"Poisson_statedict\" + img_data_key + f\"-seed{random_seed} + \".inshallah\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poisson_model_config = {\n",
    "    \"layers\": 4,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"gamma_readout\": 0.78,\n",
    "    \"init_mu_range\": 0.55,\n",
    "    \"init_sigma\": 0.4,\n",
    "    'grid_mean_predictor': {'type': 'cortex',\n",
    "                              'input_dimensions': 2,\n",
    "                              'hidden_layers': 0,\n",
    "                              'hidden_features': 0,\n",
    "                              'final_tanh': False},\n",
    "    \"input_kern\": 15,\n",
    "    \"gamma_input\": 1,\n",
    "    \"hidden_kern\": 13,\n",
    "    \"depth_separable\": True,\n",
    "    \"modulator_kwargs\": modulator_kwargs,\n",
    "    \"shifter_kwargs\": shifter_kwargs,  \n",
    "}\n",
    "\n",
    "poisson_model = SE2DFullGaussian2d_Poisson().build_model(img_dataloaders, random_seed, **poisson_model_config)\n",
    "poisson_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score, output, state_dict = standard_trainer(poisson_model,\n",
    "                                             img_dataloaders,\n",
    "                                             random_seed,\n",
    "                                             loss_function=\"PoissonLoss\",\n",
    "                                             track_training=True, )\n",
    "poisson_model.eval();\n",
    "# torch.save(state_dict, \"Poisson_statedict\" + img_data_key + \".inshallah\")\n",
    "\n",
    "\n",
    "# poisson_model.load_state_dict(torch.load(\"Poisson_statedict\" + img_data_key + \".inshallah\"))\n",
    "# poisson_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_correlation': array([-0.00216921,  0.06089262,  0.07287578,  0.09017557,  0.11448877,\n",
       "         0.12299193,  0.14777163,  0.17114505,  0.19159639,  0.21444872,\n",
       "         0.226796  ,  0.2436114 ,  0.25637776,  0.2629218 ,  0.27408484,\n",
       "         0.2732739 ,  0.28695077,  0.2864941 ,  0.2904621 ,  0.29799125,\n",
       "         0.2989345 ,  0.29993096,  0.30322784,  0.306771  ,  0.30526882,\n",
       "         0.30340692,  0.30748805,  0.30622983,  0.3083354 ,  0.31233382,\n",
       "         0.3139222 ,  0.31518897,  0.31230223,  0.31495655,  0.318402  ,\n",
       "         0.31611818,  0.31726065,  0.3171519 ,  0.31794217,  0.318402  ,\n",
       "         0.31376648,  0.3244521 ,  0.31940612,  0.32657978,  0.3215325 ,\n",
       "         0.32570863,  0.3239352 ,  0.32291067,  0.32657978,  0.32356533,\n",
       "         0.32605797,  0.32780504,  0.3246255 ,  0.32496527,  0.32512647,\n",
       "         0.32743704], dtype=float32),\n",
       " 'val_loss': array([4523065. , 2475356.2, 2464938.5, 2454380.5, 2422110.5, 2448570.2,\n",
       "        2380002.5, 2359384.2, 2326209.5, 2291545.5, 2275843.5, 2247989.5,\n",
       "        2229100.5, 2219726.8, 2198571.5, 2213462. , 2172455.5, 2186573.8,\n",
       "        2174763.8, 2159633.2, 2159043.5, 2159457. , 2151338.5, 2142980.5,\n",
       "        2150338.5, 2157931.5, 2150942.2, 2145603.8, 2149118.8, 2133266.5,\n",
       "        2135365.5, 2131033.2, 2139440.8, 2139164.5, 2121950. , 2131259. ,\n",
       "        2126163. , 2134908.5, 2123299. , 2121950. , 2137814.5, 2109876. ,\n",
       "        2129886.5, 2108896.2, 2124483. , 2106250.2, 2114610.5, 2115973.2,\n",
       "        2108896.2, 2115160.5, 2104366.8, 2100218. , 2114629.5, 2110148.5,\n",
       "        2109753.5, 2104880. ], dtype=float32),\n",
       " 'train_loss': array([40846644., 22528398., 22345140., 22239252., 21965224., 22124994.,\n",
       "        21473530., 21275482., 20952694., 20566532., 20373322., 20040616.,\n",
       "        19792282., 19673228., 19447516., 19465218., 19131114., 19253208.,\n",
       "        19102808., 18860118., 18787244., 18811408., 18679836., 18578364.,\n",
       "        18587190., 18582934., 18526000., 18473752., 18657004., 18354588.,\n",
       "        18359218., 18290440., 18348586., 18296958., 18197576., 18119764.,\n",
       "        18124930., 18133332., 18097894., 18197576., 18282880., 17895174.,\n",
       "        17994616., 17903320., 17973250., 17837070., 17776134., 17809742.,\n",
       "        17903318., 17838936., 17783328., 17795326., 17759352., 17792904.,\n",
       "        17774310., 17724062.], dtype=float32),\n",
       " 'validation_corr': 0.32780504}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32780504"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_correlation 0.32643822\n",
    "\n",
    "val_loss 2107371.0\n",
    "\n",
    "train_loss 17724226.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare DEIs/MEIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = np.array([(dat[\"animal_id\"] == imagenet_key[\"animal_id\"]) & (dat[\"session\"] != imagenet_key[\"session\"]) & (dat[\"scan_idx\"] != imagenet_key[\"scan_idx\"]) for dat in datasets])\n",
    "dei_key = np.array(datasets)[idx].item()\n",
    "\n",
    "assert dei_key[\"scan_purpose\"] == \"dei_control_pair\"\n",
    "paths = [\"./data/static{}-{}-{}-GrayImageNetDEIInfo-7bed7f7379d99271be5d144e5e59a8e7.zip\".format(dei_key[\"animal_id\"], dei_key[\"session\"], dei_key[\"scan_idx\"])]\n",
    "dei_data_key = extract_data_key(paths[0])\n",
    "\n",
    "dataset_config = {'paths': paths, \n",
    "                  'batch_size': 64, \n",
    "                  'seed': random_seed,\n",
    "                  'return_test_sampler': True,\n",
    "                  'tier': \"test\",\n",
    "                  'loader_outputs': [\"images\", 'responses', 'trial_idx', \"dei_unit_ids\", \"dei_src_unit_ids\", \"dei_mean_distances\"],\n",
    "                  'normalize': True,\n",
    "                  'exclude': [\"images\", \"trial_idx\", \"dei_unit_ids\", \"dei_src_unit_ids\", \"dei_mean_distances\"],\n",
    "                  'subtract_behavior_mean': True}\n",
    "\n",
    "dei_dataloaders = static_loaders(**dataset_config)\n",
    "\n",
    "dei_dataset = dei_dataloaders[\"test\"][dei_data_key].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, responses, trial_idxs, dei_unit_ids, dei_src_unit_ids, dei_mean_distances = [], [], [], [], [], []\n",
    "for image, response, trial_idx, dei_unit_id, dei_src_unit_id, dei_mean_distance in dei_dataloaders[\"test\"][dei_data_key]:\n",
    "    if (len(response) == 20) & (torch.unique(dei_mean_distance <= 10)):\n",
    "        images.append(image)\n",
    "        responses.append(response)\n",
    "        trial_idxs.append(trial_idx)\n",
    "        dei_unit_ids.append(dei_unit_id)\n",
    "        dei_src_unit_ids.append(dei_src_unit_id)\n",
    "        dei_mean_distances.append(dei_mean_distance)\n",
    "images = torch.stack(images)\n",
    "responses = torch.stack(responses)\n",
    "trial_idxs = torch.stack(trial_idxs).cpu().data.numpy()\n",
    "dei_unit_ids = torch.stack(dei_unit_ids).cpu().data.numpy()\n",
    "dei_src_unit_ids = torch.stack(dei_src_unit_ids).cpu().data.numpy()\n",
    "dei_mean_distances = torch.stack(dei_mean_distances).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get possible unit ids (in the source-dataset frame)\n",
    "possible_src_unit_ids = np.unique(dei_src_unit_ids, axis=1).squeeze()\n",
    "\n",
    "# Sort according to mean distances (increasing)\n",
    "src_sort_idx = np.argsort(np.unique(dei_mean_distances, axis=1).squeeze())\n",
    "possible_src_unit_ids = possible_src_unit_ids[src_sort_idx]\n",
    "\n",
    "# Remove duplicates (from several DEIs/MEI)\n",
    "_, idx = np.unique(possible_src_unit_ids, return_index=True)\n",
    "possible_src_unit_ids = possible_src_unit_ids[np.sort(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zig_model = Ensemble(zig_se2d_fullgaussian2d, zig_model_config, img_dataloaders, \"ZIG_statedict\" + img_data_key, np.arange(5), device=device)\n",
    "poisson_model = Ensemble(poisson_se2d_fullgaussian2d, poisson_model_config, img_dataloaders, \"Poisson_statedict\" + img_data_key, np.arange(5), device=device)\n",
    "\n",
    "# zig_model.shifter = None\n",
    "# poisson_model.shifter = None\n",
    "# poisson_model.modulator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zig_means = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "zig_variances = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "poisson_means = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "poisson_variances = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "real_resp_means = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "real_resp_vars = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "imgs = np.full((3, len(possible_src_unit_ids), 1, 36, 64), np.nan)\n",
    "for i, possible_src_unit_id in enumerate(possible_src_unit_ids):\n",
    "    image_idx = np.unique(np.where(dei_src_unit_ids == possible_src_unit_id)[0])\n",
    "\n",
    "    dei_neuron_id = np.unique(dei_unit_ids[image_idx]).item()\n",
    "    src_neuron_id = np.unique(dei_src_unit_ids[image_idx]).item()\n",
    "    src_neuron_idx = np.where(img_dataset.neurons.unit_ids == src_neuron_id)[0].item()\n",
    "    dei_neuron_idx = np.where(dei_dataset.neurons.unit_ids == dei_neuron_id)[0].item()\n",
    "\n",
    "    img = torch.unique(images[image_idx], dim=1).squeeze(1)\n",
    "    mei_dei_idx = [0, 1, 2]\n",
    "    if len(image_idx) != 3:\n",
    "        idx = np.where(np.isin(dei_dataset.trial_info.trial_idx, trial_idxs[image_idx]))[0]\n",
    "        if 'mask_fixed_mei' in np.unique(dei_dataset.trial_info.frame_image_class[idx]):\n",
    "            mei_dei_idx = [0, 1] if len(image_idx) == 2 else [0]\n",
    "        else:\n",
    "            mei_dei_idx = [1, 2] if len(image_idx) == 2 else [1]\n",
    "    imgs[mei_dei_idx, i, :, :, :] = img.cpu().data\n",
    "    \n",
    "    # TODO: Keep this line?\n",
    "#     img = torch.stack([((im - im.mean()) / (im.std())) for im in img.squeeze()])[:, None]\n",
    "\n",
    "    behavior = torch.zeros((img.shape[0], 3)).to(device)\n",
    "    pupil_center = torch.zeros((img.shape[0], 2)).to(device)\n",
    "    \n",
    "    zig_means_ = zig_model.predict_mean(img, data_key=img_data_key, behavior=behavior, pupil_center=pupil_center).cpu().data.numpy()\n",
    "    zig_variances_ = zig_model.predict_variance(img, data_key=img_data_key, behavior=behavior, pupil_center=pupil_center).cpu().data.numpy()\n",
    "    poisson_means_ = poisson_model.predict_mean(img, data_key=img_data_key, behavior=behavior, pupil_center=pupil_center).cpu().data.numpy()\n",
    "    poisson_variances_ = poisson_model.predict_variance(img, data_key=img_data_key, behavior=behavior, pupil_center=pupil_center).cpu().data.numpy()\n",
    "\n",
    "    zig_means[mei_dei_idx, i] = zig_means_[:, src_neuron_idx]\n",
    "    zig_variances[mei_dei_idx, i] = zig_variances_[:, src_neuron_idx]\n",
    "    poisson_means[mei_dei_idx, i] = poisson_means_[:, src_neuron_idx]\n",
    "    poisson_variances[mei_dei_idx, i] = poisson_variances_[:, src_neuron_idx]\n",
    "    \n",
    "    real_resp_means[mei_dei_idx, i] = np.mean(responses[image_idx].cpu().data.numpy(), axis=1)[:, dei_neuron_idx]\n",
    "    real_resp_vars[mei_dei_idx, i] = np.var(responses[image_idx].cpu().data.numpy(), axis=1)[:, dei_neuron_idx]\n",
    "keep_idx = ~np.isnan(zig_means).any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Zhiwei Model with Konstantin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(r\"group233_mei_dei_resps.pkl\", \"rb\") as input_file:\n",
    "    e = pickle.load(input_file).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(15, 10), dpi=150, sharex=True, sharey=True)\n",
    "fontsize = 10\n",
    "\n",
    "\n",
    "y_zhiwei = e / e[0, :]\n",
    "y_zig = zig_means / zig_means[0, :]\n",
    "y_zig = y_zig[:, keep_idx]\n",
    "y_poisson = poisson_means / poisson_means[0, :]\n",
    "y_poisson = y_poisson[:, keep_idx]\n",
    "y_real = real_resp_means / real_resp_means[0, :]\n",
    "y_real = y_real[:, keep_idx]\n",
    "x = np.arange(y_real.shape[1])\n",
    "\n",
    "# Zhiwei\n",
    "for i in range(3):\n",
    "    axes[0].plot(x, y_zhiwei[i,:], ls=\"\", marker=\"x\")\n",
    "\n",
    "# ZIG\n",
    "for i in range(3):\n",
    "    axes[1].plot(x, y_zig[i,:], ls=\"\", marker=\"x\")\n",
    "    \n",
    "# Poisson\n",
    "for i in range(3):\n",
    "    axes[2].plot(x, y_poisson[i,:], ls=\"\", marker=\"x\")\n",
    "    axes[2].ticklabel_format(useOffset=False)\n",
    "    \n",
    "# Real data\n",
    "for i, label in enumerate([\"MEI\", \"DEI1\", \"DEI2\"]):\n",
    "    axes[3].plot(x, y_real[i,:], ls=\"\", marker=\"x\", label=label)\n",
    "    \n",
    "    \n",
    "axes[0].set_title(\"Zhiwei model\", fontsize=fontsize*1.3)\n",
    "axes[1].set_title(\"ZIG model\", fontsize=fontsize*1.3)\n",
    "axes[2].set_title(\"Poisson model\", fontsize=fontsize*1.3)\n",
    "axes[3].set_title(\"Real data  (averaged over 20 repeats)\", fontsize=fontsize*1.3)\n",
    "axes[3].set_xlabel(\"neurons\", fontsize=fontsize*1.2)\n",
    "axes[3].set_ylabel(r\"$\\frac{resp}{resp(MEI)}$\", fontsize=fontsize*1.2)\n",
    "\n",
    "axes[0].set(ylim=[0, 1.5])\n",
    "\n",
    "# axes[3].legend(bbox_to_anchor=(0.15, 1., 0, 0), frameon=True, fontsize=fontsize*.8)\n",
    "axes[3].legend(bbox_to_anchor=(0.1, 1.1, 0, 0), frameon=True, fontsize=fontsize*.8)\n",
    "\n",
    "sns.despine(trim=True)\n",
    "# fig.savefig(\"Zhiwei_Model_Comparison\" + \".png\", bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_zhiwei[0], y_poisson[0])\n",
    "ax.scatter(y_zhiwei[0], y_zig[0])\n",
    "ax.scatter(y_zhiwei[0], y_real[0])\n",
    "ax.plot([ax.get_xlim()[0], ax.get_xlim()[1]], [ax.get_ylim()[0], ax.get_ylim()[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zig_zhiwei, poisson_zhiwei, zig_real, poisson_real, zhiwei_real = [], [], [], [], []\n",
    "for i in range(e.shape[-1]):\n",
    "    zig_zhiwei_, p = spearmanr(e[:, i], zig_means[:, keep_idx][:, i], axis=0)\n",
    "    poisson_zhiwei_, p = spearmanr(e[:, i], poisson_means[:, keep_idx][:, i], axis=0)\n",
    "    zig_real_, p = spearmanr(real_resp_means[:, keep_idx][:, i], zig_means[:, keep_idx][:, i], axis=0)\n",
    "    poisson_real_, p = spearmanr(real_resp_means[:, keep_idx][:, i], poisson_means[:, keep_idx][:, i], axis=0)\n",
    "    zhiwei_real_, p = spearmanr(real_resp_means[:, keep_idx][:, i], e[:, i], axis=0)\n",
    "    \n",
    "    zig_zhiwei.append(zig_zhiwei_)\n",
    "    poisson_zhiwei.append(poisson_zhiwei_)\n",
    "    zig_real.append(zig_real_)\n",
    "    poisson_real.append(poisson_real_)\n",
    "    zhiwei_real.append(zhiwei_real_)\n",
    "\n",
    "print(\"ZIG     |  Zhiwei: {:.5f}\".format(np.mean(zig_zhiwei)))\n",
    "print(\"Poisson |  Zhiwei: {:.5f}\".format(np.mean(poisson_zhiwei)))\n",
    "print(\"ZIG     |  Real:   {:.5f}\".format(np.mean(zig_real)))\n",
    "print(\"Poisson |  Real:   {:.5f}\".format(np.mean(poisson_real)))\n",
    "print(\"Zhiwei  |  Real:   {:.5f}\".format(np.mean(zhiwei_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zig_zhiwei = np.mean(corr(e, zig_means[:, keep_idx], axis=0))\n",
    "poisson_zhiwei = np.mean(corr(e, poisson_means[:, keep_idx], axis=0))\n",
    "zig_real = np.mean(corr(real_resp_means[:, keep_idx], zig_means[:, keep_idx], axis=0))\n",
    "poisson_real = np.mean(corr(real_resp_means[:, keep_idx], poisson_means[:, keep_idx], axis=0))\n",
    "zhiwei_real = np.mean(corr(real_resp_means[:, keep_idx], e, axis=0))\n",
    "\n",
    "print(\"ZIG     |  Zhiwei: {:.5f}\".format(np.mean(zig_zhiwei)))\n",
    "print(\"Poisson |  Zhiwei: {:.5f}\".format(np.mean(poisson_zhiwei)))\n",
    "print(\"ZIG     |  Real:   {:.5f}\".format(np.mean(zig_real)))\n",
    "print(\"Poisson |  Real:   {:.5f}\".format(np.mean(poisson_real)))\n",
    "print(\"Zhiwei  |  Real:   {:.5f}\".format(np.mean(zhiwei_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9, 3), dpi=150)\n",
    "color = \"navy\"\n",
    "ec=\"white\"\n",
    "fontsize = 15\n",
    "\n",
    "axes[0].scatter(real_resp_means.flatten(), real_resp_vars.flatten(), color=color, ec=ec)\n",
    "axes[0].set_xlabel(\"Means\", fontsize=fontsize)\n",
    "axes[0].set_ylabel(\"Variances\", fontsize=fontsize)\n",
    "axes[0].set_title(\"Real Data\", fontsize=fontsize*1.3)\n",
    "\n",
    "axes[1].scatter(zig_means.flatten(), zig_variances.flatten(), color=color, ec=ec)\n",
    "axes[1].set_title(\"ZIG\", fontsize=fontsize*1.3)\n",
    "axes[1].plot([axes[1].get_xlim()[0], axes[1].get_xlim()[1]], [axes[1].get_xlim()[0], axes[1].get_xlim()[1]], ls=\"--\", color=\"grey\", label=\"Poisson\")\n",
    "# axes[1].set(xlim=[0, 15], ylim=[0, 400])\n",
    "axes[1].legend(frameon=False, bbox_to_anchor=[.4,.8,0,0])\n",
    "sns.despine(trim=True)\n",
    "\n",
    "# fig.savefig(\"mean_variance_comparison\" + \".png\", bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9, 3), dpi=150)\n",
    "color = \"navy\"\n",
    "ec=\"white\"\n",
    "fontsize = 15\n",
    "\n",
    "axes[0].plot(real_resp_means, real_resp_vars, marker=\"\", lw=1)\n",
    "axes[0].set_xlabel(\"Means\", fontsize=fontsize)\n",
    "axes[0].set_ylabel(\"Variances\", fontsize=fontsize)\n",
    "axes[0].set_title(\"Real Data\", fontsize=fontsize*1.3)\n",
    "\n",
    "axes[1].plot(zig_means, zig_variances, marker=\"\", lw=1)\n",
    "axes[1].set_title(\"ZIG\", fontsize=fontsize*1.3)\n",
    "axes[1].plot([axes[1].get_xlim()[0], axes[1].get_xlim()[1]], [axes[1].get_xlim()[0], axes[1].get_xlim()[1]], ls=\"--\", color=\"grey\", label=\"Poisson\")\n",
    "# axes[1].set(xlim=[0, 15], ylim=[0, 400])\n",
    "axes[1].legend(frameon=False, bbox_to_anchor=[.4,.8,0,0])\n",
    "sns.despine(trim=True)\n",
    "\n",
    "# fig.savefig(\"mean_variance_comparison\" + \".png\", bbox_inches=\"tight\", transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
