{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datajoint as dj\n",
    "dj.config['database.host'] = os.environ['DJ_HOST']\n",
    "dj.config['database.user'] = os.environ['DJ_USERNAME']\n",
    "dj.config['database.password'] = os.environ['DJ_PASSWORD']\n",
    "dj.config['enable_python_native_blobs'] = True\n",
    "dj.config['display.limit'] = 200\n",
    "        \n",
    "name = 'mvi'\n",
    "os.environ[\"DJ_SCHEMA_NAME\"] = f\"metrics_{name}\"\n",
    "dj.config[\"nnfabrik.schema_name\"] = os.environ[\"DJ_SCHEMA_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting konstantin@134.76.19.44:3306\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle \n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"figure.facecolor\"] = 'w'\n",
    "mpl.rcParams[\"axes.facecolor\"] = 'w'\n",
    "mpl.rcParams[\"savefig.facecolor\"] = 'w'\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "mpl.rcParams[\"figure.figsize\"] = (3, 3)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from neuralmetrics.utils import extract_data_key\n",
    "from neuralmetrics.models.direct import ZIG\n",
    "from neuralmetrics.training.losses import ZIGLoss\n",
    "from neuralmetrics.training.trainers import nn_zig_trainer\n",
    "from neuralmetrics.datasets import static_loaders\n",
    "from neuralmetrics.models.neuralnet import zig_se2d_fullgaussian2d\n",
    "from neuralpredictors.measures import corr\n",
    "\n",
    "from dataport.bcm.static import PreprocessedMouseData\n",
    "\n",
    "random_seed = 27121992\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =  [{'animal_id': 26614,\n",
    "              'session': 1,\n",
    "              'scan_idx': 16,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 26614,\n",
    "              'session': 2,\n",
    "              'scan_idx': 17,\n",
    "              'scan_purpose': 'dei_control_pair'},\n",
    "             {'animal_id': 26726,\n",
    "              'session': 6,\n",
    "              'scan_idx': 11,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 26726,\n",
    "              'session': 7,\n",
    "              'scan_idx': 13,\n",
    "              'scan_purpose': 'dei_control_pair'},\n",
    "             {'animal_id': 26942,\n",
    "              'session': 1,\n",
    "              'scan_idx': 11,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 26942,\n",
    "              'session': 2,\n",
    "              'scan_idx': 8,\n",
    "              'scan_purpose': 'dei_control_pair'},\n",
    "             {'animal_id': 27468,\n",
    "              'session': 3,\n",
    "              'scan_idx': 12,\n",
    "              'scan_purpose': 'imagenet'},\n",
    "             {'animal_id': 27468,\n",
    "              'session': 4,\n",
    "              'scan_idx': 7,\n",
    "              'scan_purpose': 'dei_control_pair'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_key = datasets[0]\n",
    "assert imagenet_key[\"scan_purpose\"] == \"imagenet\"\n",
    "paths = [\"./data/static{}-{}-{}-GrayImageNet-7bed7f7379d99271be5d144e5e59a8e7.zip\".format(imagenet_key[\"animal_id\"], imagenet_key[\"session\"], imagenet_key[\"scan_idx\"])]\n",
    "img_data_key = extract_data_key(paths[0])\n",
    "\n",
    "dataset_config = {'paths': paths, \n",
    "                  'batch_size': 64, \n",
    "                  'seed': random_seed,\n",
    "                  'loader_outputs': [\"images\", \"responses\"],\n",
    "                  'normalize': True,\n",
    "                  'exclude': [\"images\"]\n",
    "                  }\n",
    "    \n",
    "img_dataloaders = static_loaders(**dataset_config)\n",
    "img_dataset = img_dataloaders[\"test\"][img_data_key].dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/neuralpredictors/layers/cores/conv2d.py:127: UserWarning: The averaged value of regularizer will be used.\n",
      "  warnings.warn(\"The averaged value of regularizer will be used.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "loc = np.exp(-10)\n",
    "\n",
    "model_config = {\n",
    "    \"layers\": 4,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"feature_reg_weight\": 0.78,\n",
    "    \"init_mu_range\": 0.55,\n",
    "    \"init_sigma\": 0.4,\n",
    "    'grid_mean_predictor': {'type': 'cortex',\n",
    "                              'input_dimensions': 2,\n",
    "                              'hidden_layers': 0,\n",
    "                              'hidden_features': 0,\n",
    "                              'final_tanh': False},\n",
    "    'zero_thresholds': {img_data_key: loc},\n",
    "\n",
    "    \"input_kern\": 15,\n",
    "    \"gamma_input\": 1,\n",
    "    \"hidden_kern\": 13,\n",
    "    \"depth_separable\": True,\n",
    "}\n",
    "\n",
    "\n",
    "model = zig_se2d_fullgaussian2d(img_dataloaders, random_seed, **model_config)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, output, state_dict = nn_zig_trainer(model,\n",
    "                                           img_dataloaders,\n",
    "                                           random_seed, \n",
    "                                           loss_function=\"ZIGLoss\", \n",
    "                                           stop_function=\"get_loss\", \n",
    "                                           track_training=True, \n",
    "                                           maximize=False)\n",
    "model.eval();\n",
    "# torch.save(state_dict, \"MVI_statedict_\" + img_data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_unnormimage\n"
     ]
    }
   ],
   "source": [
    "norm_image = \"_unnormimage\" if \"images\" in dataset_config[\"exclude\"] else \"_normimage\"\n",
    "\n",
    "model.load_state_dict(torch.load(\"MVI_statedict_\" + img_data_key + norm_image))\n",
    "model.eval();\n",
    "print(norm_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning only test sampler with repeats...\n"
     ]
    }
   ],
   "source": [
    "idx = np.array([(dat[\"animal_id\"] == imagenet_key[\"animal_id\"]) & (dat[\"session\"] != imagenet_key[\"session\"]) & (dat[\"scan_idx\"] != imagenet_key[\"scan_idx\"]) for dat in datasets])\n",
    "dei_key = np.array(datasets)[idx].item()\n",
    "\n",
    "assert dei_key[\"scan_purpose\"] == \"dei_control_pair\"\n",
    "paths = [\"./data/static{}-{}-{}-GrayImageNetDEIInfo-7bed7f7379d99271be5d144e5e59a8e7.zip\".format(dei_key[\"animal_id\"], dei_key[\"session\"], dei_key[\"scan_idx\"])]\n",
    "dei_data_key = extract_data_key(paths[0])\n",
    "\n",
    "dataset_config = {'paths': paths, \n",
    "                  'batch_size': 64, \n",
    "                  'seed': random_seed,\n",
    "                  'return_test_sampler': True,\n",
    "                  'tier': \"test\",\n",
    "                  'loader_outputs': [\"images\", 'responses', 'trial_idx', \"dei_unit_ids\", \"dei_src_unit_ids\", \"dei_mean_distances\"],\n",
    "                  'normalize': True,\n",
    "                  'exclude': [\"images\", \"trial_idx\", \"dei_unit_ids\", \"dei_src_unit_ids\", \"dei_mean_distances\"]}\n",
    "\n",
    "dei_dataloaders = static_loaders(**dataset_config)\n",
    "\n",
    "dei_dataset = dei_dataloaders[\"test\"][dei_data_key].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, responses, trial_idxs, dei_unit_ids, dei_src_unit_ids, dei_mean_distances = [], [], [], [], [], []\n",
    "for image, response, trial_idx, dei_unit_id, dei_src_unit_id, dei_mean_distance in dei_dataloaders[\"test\"][dei_data_key]:\n",
    "    if (len(response) == 20) & (torch.unique(dei_mean_distance <= 10)):\n",
    "        images.append(image)\n",
    "        responses.append(response)\n",
    "        trial_idxs.append(trial_idx)\n",
    "        dei_unit_ids.append(dei_unit_id)\n",
    "        dei_src_unit_ids.append(dei_src_unit_id)\n",
    "        dei_mean_distances.append(dei_mean_distance)\n",
    "images = torch.stack(images)\n",
    "responses = torch.stack(responses)\n",
    "trial_idxs = torch.stack(trial_idxs).cpu().data.numpy()\n",
    "dei_unit_ids = torch.stack(dei_unit_ids).cpu().data.numpy()\n",
    "dei_src_unit_ids = torch.stack(dei_src_unit_ids).cpu().data.numpy()\n",
    "dei_mean_distances = torch.stack(dei_mean_distances).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get possible unit ids (in the source-dataset frame)\n",
    "possible_src_unit_ids = np.unique(dei_src_unit_ids, axis=1).squeeze()\n",
    "\n",
    "# Sort according to mean distances (increasing)\n",
    "src_sort_idx = np.argsort(np.unique(dei_mean_distances, axis=1).squeeze())\n",
    "possible_src_unit_ids = possible_src_unit_ids[src_sort_idx]\n",
    "\n",
    "# Remove duplicates (from several DEIs/MEI)\n",
    "_, idx = np.unique(possible_src_unit_ids, return_index=True)\n",
    "possible_src_unit_ids = possible_src_unit_ids[np.sort(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "variances = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "real_resp_means = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "real_resp_vars = np.full((3, len(possible_src_unit_ids)), np.nan)\n",
    "for i, possible_src_unit_id in enumerate(possible_src_unit_ids):\n",
    "    image_idx = np.unique(np.where(dei_src_unit_ids == possible_src_unit_id)[0])\n",
    "    \n",
    "    # skip missing data\n",
    "    if len(image_idx) != 3:\n",
    "        continue\n",
    "\n",
    "    dei_neuron_id = np.unique(dei_unit_ids[image_idx]).item()\n",
    "    src_neuron_id = np.unique(dei_src_unit_ids[image_idx]).item()\n",
    "    src_neuron_idx = np.where(img_dataset.neurons.unit_ids == src_neuron_id)[0].item()\n",
    "    dei_neuron_idx = np.where(dei_dataset.neurons.unit_ids == dei_neuron_id)[0].item()\n",
    "\n",
    "    img = torch.unique(images[image_idx], dim=1).squeeze(1)\n",
    "    \n",
    "    # TODO: Keep this line?\n",
    "#     img = torch.stack([((im - im.mean()) / (im.std())) for im in img.squeeze()])[:, None]\n",
    "\n",
    "    \n",
    "    means_ = model.predict_mean(img, data_key=img_data_key).squeeze().cpu().data.numpy()\n",
    "    variances_ = model.predict_variance(img, data_key=img_data_key).squeeze().cpu().data.numpy()\n",
    "\n",
    "    means[:, i] = means_[:, src_neuron_idx]\n",
    "    variances[:, i] = variances_[:, src_neuron_idx]\n",
    "    \n",
    "    real_resp_means[:, i] = np.mean(responses[image_idx].cpu().data.numpy(), axis=1)[:, dei_neuron_idx]\n",
    "    real_resp_vars[:, i] = np.var(responses[image_idx].cpu().data.numpy(), axis=1)[:, dei_neuron_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Zhiwei Model with Konstantin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"group233_mei_dei_resps.pkl\", \"rb\") as input_file:\n",
    "    e = pickle.load(input_file).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 11), dpi=100, sharex=True)\n",
    "fontsize = 15\n",
    "\n",
    "\n",
    "x = np.arange(e.shape[1])\n",
    "y_zhiwei = e / e[0, :]\n",
    "y_konstantin = means / means[0, :]\n",
    "y_konstantin = y_konstantin[:, ~np.isnan(y_konstantin[0, :])]\n",
    "y_real = real_resp_means / real_resp_means[0, :]\n",
    "y_real = y_real[:, ~np.isnan(y_real[0, :])]\n",
    "\n",
    "# Zhiwei\n",
    "for i in range(3):\n",
    "    axes[0].plot(x, y_zhiwei[i,:], ls=\"\", marker=\"x\")\n",
    "\n",
    "# Konstantin\n",
    "for i in range(3):\n",
    "    axes[1].plot(x, y_konstantin[i,:], ls=\"\", marker=\"x\")\n",
    "    \n",
    "# Real data\n",
    "for i, label in enumerate([\"MEI\", \"DEI1\", \"DEI2\"]):\n",
    "    axes[2].plot(x, y_real[i,:], ls=\"\", marker=\"x\", label=label)\n",
    "    \n",
    "    \n",
    "axes[0].set_title(\"Zhiwei model\", fontsize=fontsize*1.3)\n",
    "axes[1].set_title(\"Konstantin model\", fontsize=fontsize*1.3)\n",
    "axes[2].set_title(\"Real data (averaged over 20 repeats)\", fontsize=fontsize*1.3)\n",
    "axes[2].set_xlabel(\"neurons\", fontsize=fontsize)\n",
    "axes[2].set_ylabel(r\"$\\frac{resp}{resp(MEI)}$\", fontsize=fontsize)\n",
    "\n",
    "# axes[1].set(ylim=[0, 6])\n",
    "\n",
    "axes[2].legend(bbox_to_anchor=(0.15, 1., 0, 0), frameon=False, fontsize=fontsize*.8)\n",
    "sns.despine(trim=True)\n",
    "# fig.savefig(\"Zhiwei_Model_Comparison\" + \".png\", bbox_inches=\"tight\", transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ks, c_zs = [], []\n",
    "for i in range(y_real.shape[-1]):\n",
    "    c_k, p = spearmanr(y_real[:, i], y_konstantin[:, i], axis=0)\n",
    "    c_z, p = spearmanr(y_real[:, i], y_zhiwei[:, i], axis=0)\n",
    "    c_ks.append(c_k)\n",
    "    c_zs.append(c_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(c_ks), np.mean(c_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_k = np.mean(corr(real_resp_means[:, ~np.isnan(real_resp_means[0, :])], means[:, ~np.isnan(real_resp_means[0, :])], axis=0))\n",
    "co_z = np.mean(corr(real_resp_means[:, ~np.isnan(real_resp_means[0, :])], e, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_k, co_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
