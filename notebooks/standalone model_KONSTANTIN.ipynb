{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting zhiwei@at-database.ad.bcm.edu:3306\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import pickle\n",
    "from staticnet.base import CorePlusReadout2d, Elu1\n",
    "from staticnet.cores import GaussianLaplaceCore\n",
    "from staticnet.readouts import SpatialTransformerPyramid2dReadout\n",
    "from staticnet.shifters import MLPShifter\n",
    "from staticnet.modulators import MLPModulator\n",
    "from featurevis import models\n",
    "import datajoint as dj\n",
    "base = dj.create_virtual_module('neurostatic_base', 'neurostatic_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_network(configs):\n",
    "    Core = GaussianLaplaceCore\n",
    "    Readout = SpatialTransformerPyramid2dReadout\n",
    "    Shifter = MLPShifter\n",
    "    Modulator = MLPModulator\n",
    "\n",
    "    core = Core(input_channels=configs['img_shape'][1], **configs['core_key'])\n",
    "    ro_in_shape = CorePlusReadout2d.get_readout_in_shape(core, configs['img_shape'])\n",
    "    readout = Readout(ro_in_shape, configs['n_neurons'], **configs['ro_key'])\n",
    "    shifter = Shifter(configs['n_neurons'], 2, **configs['shift_key'])\n",
    "    modulator = Modulator(configs['n_neurons'], 3, **configs['mod_key'])\n",
    "    model = CorePlusReadout2d(core, readout, nonlinearity=Elu1(), shifter=shifter, modulator=modulator)\n",
    "    return model\n",
    "\n",
    "def load_network(configs, state_dict):\n",
    "    model = build_network(configs)\n",
    "    try:\n",
    "        state_dict = {k: torch.as_tensor(state_dict[k][0].copy()) for k in state_dict.dtype.names}\n",
    "    except AttributeError:\n",
    "        state_dict = {k: torch.as_tensor(state_dict[k].copy()) for k in state_dict.keys()}\n",
    "    mod_state_dict = model.state_dict()\n",
    "    for k in set(mod_state_dict) - set(state_dict):\n",
    "        log.warning('Could not find paramater {} setting to initialization value'.format(repr(k)))\n",
    "        state_dict[k] = mod_state_dict[k]\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load target neurons and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurons and images of interest\n",
    "imgs = torch.load(\"/src/static-networks/imgs.pt\")\n",
    "src_n_ids = torch.load(\"/src/static-networks/src_n_ids.pt\")\n",
    "                       \n",
    "# Load model architecture configurations\n",
    "with open('/src/static-networks/my_notebooks/group233_model_configs.pkl', 'rb') as handle:\n",
    "    configs = pickle.load(handle)\n",
    "    \n",
    "# Load trained model state_dict\n",
    "with open('/src/static-networks/my_notebooks/group233_model_state_dict_ls.pkl', 'rb') as handle:\n",
    "    state_dict_ls = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build network and load trained model state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-01-2023:08:56:34 INFO     cores.py             101:\t Ignoring input {'core_hash': '28bc2fa358337c5012278f899b5b6947'} when creating GaussianLaplaceCore\n",
      "05-01-2023:08:56:34 INFO     readouts.py          146:\t Ignoring input {'ro_hash': 'a206f6da6a16ea14081062a1e2436b48', 'ro_type': 'SpatialTransformerPyramid2d'} when creating SpatialTransformerPyramid2dReadout\n",
      "05-01-2023:08:56:34 INFO     shifters.py           55:\t Ignoring input {'shift_hash': '05c69a4aeaeea5e48fa8fc5e70181d67', 'shift_type': 'MLP'} when creating MLPShifter\n",
      "05-01-2023:08:56:34 INFO     shifters.py           27:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     modulators.py         47:\t Ignoring input {'mod_hash': 'a757e992ae449e3057ff1d512a51bd1e', 'mod_type': 'MLP'} when creating MLPModulator\n",
      "05-01-2023:08:56:34 INFO     modulators.py         18:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     cores.py             101:\t Ignoring input {'core_hash': '28bc2fa358337c5012278f899b5b6947'} when creating GaussianLaplaceCore\n",
      "05-01-2023:08:56:34 INFO     readouts.py          146:\t Ignoring input {'ro_hash': 'a206f6da6a16ea14081062a1e2436b48', 'ro_type': 'SpatialTransformerPyramid2d'} when creating SpatialTransformerPyramid2dReadout\n",
      "05-01-2023:08:56:34 INFO     shifters.py           55:\t Ignoring input {'shift_hash': '05c69a4aeaeea5e48fa8fc5e70181d67', 'shift_type': 'MLP'} when creating MLPShifter\n",
      "05-01-2023:08:56:34 INFO     shifters.py           27:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     modulators.py         47:\t Ignoring input {'mod_hash': 'a757e992ae449e3057ff1d512a51bd1e', 'mod_type': 'MLP'} when creating MLPModulator\n",
      "05-01-2023:08:56:34 INFO     modulators.py         18:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     cores.py             101:\t Ignoring input {'core_hash': '28bc2fa358337c5012278f899b5b6947'} when creating GaussianLaplaceCore\n",
      "05-01-2023:08:56:34 INFO     readouts.py          146:\t Ignoring input {'ro_hash': 'a206f6da6a16ea14081062a1e2436b48', 'ro_type': 'SpatialTransformerPyramid2d'} when creating SpatialTransformerPyramid2dReadout\n",
      "05-01-2023:08:56:34 INFO     shifters.py           55:\t Ignoring input {'shift_hash': '05c69a4aeaeea5e48fa8fc5e70181d67', 'shift_type': 'MLP'} when creating MLPShifter\n",
      "05-01-2023:08:56:34 INFO     shifters.py           27:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     modulators.py         47:\t Ignoring input {'mod_hash': 'a757e992ae449e3057ff1d512a51bd1e', 'mod_type': 'MLP'} when creating MLPModulator\n",
      "05-01-2023:08:56:34 INFO     modulators.py         18:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     cores.py             101:\t Ignoring input {'core_hash': '28bc2fa358337c5012278f899b5b6947'} when creating GaussianLaplaceCore\n",
      "05-01-2023:08:56:34 INFO     readouts.py          146:\t Ignoring input {'ro_hash': 'a206f6da6a16ea14081062a1e2436b48', 'ro_type': 'SpatialTransformerPyramid2d'} when creating SpatialTransformerPyramid2dReadout\n",
      "05-01-2023:08:56:34 INFO     shifters.py           55:\t Ignoring input {'shift_hash': '05c69a4aeaeea5e48fa8fc5e70181d67', 'shift_type': 'MLP'} when creating MLPShifter\n",
      "05-01-2023:08:56:34 INFO     shifters.py           27:\t Ignoring input {} when creating MLP\n",
      "05-01-2023:08:56:34 INFO     modulators.py         47:\t Ignoring input {'mod_hash': 'a757e992ae449e3057ff1d512a51bd1e', 'mod_type': 'MLP'} when creating MLPModulator\n",
      "05-01-2023:08:56:34 INFO     modulators.py         18:\t Ignoring input {} when creating MLP\n"
     ]
    }
   ],
   "source": [
    "# Load model with trained state_dict from 4 different initialization seeds\n",
    "all_models = [load_network(configs, state_dict_ls[i]['model']) for i in range(len(state_dict_ls))]\n",
    "\n",
    "# Specify mean eye position\n",
    "mean_eyepos = ([0, 0])\n",
    "\n",
    "# Create model ensemble\n",
    "mean_eyepos = torch.tensor(mean_eyepos, dtype=torch.float32,\n",
    "                           device='cuda').unsqueeze(0)\n",
    "model_ensemble = models.Ensemble(all_models, configs['key']['readout_key'], eye_pos=mean_eyepos,\n",
    "                        average_batch=False, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get model predicted response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resps = []\n",
    "for i in range(len(src_n_ids)):\n",
    "    # Specify neuron_id and images\n",
    "    neuron_id = (base.Dataset.Unit & 'group_id = 233 and unit_id = {}'.format(src_n_ids[i])).fetch1('neuron_id')\n",
    "    images = imgs[i]\n",
    "\n",
    "    # Normalize each image to have average training statistics for masked images like MEI or DEI: mean = 0, std = 0.25\n",
    "    norm_images = torch.stack([((im - im.mean()) / (im.std() + 1e-9)) * 0.25 for im in images.squeeze()])[:, None]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        resp = model_ensemble(norm_images)[:, neuron_id].cpu().numpy().squeeze()\n",
    "    resps.append(resp)\n",
    "\n",
    "resps = np.stack(resps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.8476606 , 0.8277773 ],\n",
       "       [1.        , 0.82828283, 0.8701826 ],\n",
       "       [1.        , 0.88066673, 0.85804814],\n",
       "       [1.        , 0.8504938 , 0.8503026 ],\n",
       "       [1.        , 0.8448976 , 0.8603661 ],\n",
       "       [1.        , 0.8730932 , 0.8695517 ],\n",
       "       [1.        , 0.8513239 , 0.8483376 ],\n",
       "       [1.        , 0.86936873, 0.8452019 ],\n",
       "       [1.        , 0.8458835 , 0.890649  ],\n",
       "       [1.        , 0.84287995, 0.84245694],\n",
       "       [1.        , 0.85185605, 0.86849165],\n",
       "       [1.        , 0.84870005, 0.8245643 ],\n",
       "       [1.        , 0.8604489 , 0.8525374 ],\n",
       "       [1.        , 0.8468542 , 0.886497  ],\n",
       "       [1.        , 0.843001  , 0.87426955],\n",
       "       [1.        , 0.857618  , 0.8714664 ],\n",
       "       [1.        , 0.8969005 , 0.8547968 ],\n",
       "       [1.        , 0.8747891 , 0.8496681 ],\n",
       "       [1.        , 0.85644585, 0.91385823],\n",
       "       [1.        , 0.8573006 , 0.87817   ],\n",
       "       [1.        , 0.84672385, 0.8551972 ],\n",
       "       [1.        , 0.8296251 , 0.8783343 ],\n",
       "       [1.        , 0.88322324, 0.96877337],\n",
       "       [1.        , 0.8740542 , 0.84992987],\n",
       "       [1.        , 0.84849006, 0.8659669 ],\n",
       "       [1.        , 0.82880515, 0.8448749 ],\n",
       "       [1.        , 0.8559422 , 0.82553136],\n",
       "       [1.        , 0.8430941 , 0.8600862 ],\n",
       "       [1.        , 0.8670497 , 0.8474691 ],\n",
       "       [1.        , 0.8568642 , 0.84612256],\n",
       "       [1.        , 0.8364973 , 0.8385717 ],\n",
       "       [1.        , 0.8825504 , 0.83172005],\n",
       "       [1.        , 0.84771365, 0.8507492 ],\n",
       "       [1.        , 0.8037705 , 0.80611557],\n",
       "       [1.        , 0.83961093, 0.8202701 ],\n",
       "       [1.        , 0.82258373, 0.86549354],\n",
       "       [1.        , 0.8192722 , 0.851211  ],\n",
       "       [1.        , 0.8498688 , 0.83953613],\n",
       "       [1.        , 0.9152723 , 0.80261284],\n",
       "       [1.        , 0.8442482 , 0.86107117],\n",
       "       [1.        , 0.8481113 , 0.9150983 ],\n",
       "       [1.        , 0.832908  , 0.8972539 ],\n",
       "       [1.        , 0.8858195 , 0.8534034 ],\n",
       "       [1.        , 0.83939165, 0.8550103 ],\n",
       "       [1.        , 0.8681921 , 0.8591989 ],\n",
       "       [1.        , 0.88267994, 0.8492027 ],\n",
       "       [1.        , 0.8318836 , 0.86792773],\n",
       "       [1.        , 0.86835134, 0.86329865],\n",
       "       [1.        , 0.86918956, 0.8485636 ],\n",
       "       [1.        , 0.87317115, 0.83887035],\n",
       "       [1.        , 0.8706454 , 0.8459673 ],\n",
       "       [1.        , 0.8532327 , 0.8110118 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resps / resps[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/src/static-networks/my_notebooks/group233_mei_dei_resps.pkl', 'wb') as handle:\n",
    "    pickle.dump(resps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
